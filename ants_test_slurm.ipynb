{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules and set experiment-specific parameters\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join as opj\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode, JoinNode\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.interfaces.utility import IdentityInterface, Merge, Select\n",
    "from nipype.interfaces.ants import Registration, ApplyTransforms, AverageImages\n",
    "from nipype import config, logging\n",
    "\n",
    "config.enable_debug_mode()\n",
    "logging.update_logging(config)\n",
    "\n",
    "#runs out of current directory \n",
    "filepath = os.path.dirname( os.path.realpath( '__file__'))\n",
    "datadir = os.path.realpath(os.path.join(filepath, ''))\n",
    "os.chdir(datadir)\n",
    "\n",
    "subject_list = ['d701', 'd702', 'd703', 'd704', 'd705', 'd706', 'd707', \n",
    "                'd708', 'd709', 'd710', 'd711', 'd712', 'd713', 'd714', \n",
    "                'd715', 'd716', 'd717', 'd720', 'd722', 'd723', 'd724', \n",
    "                'd726', 'd727', 'd728', 'd729', 'd730', 'd731', 'd732', \n",
    "                'd734']\n",
    "\n",
    "# Rigid Reg node 1\n",
    "\n",
    "antsreg = Registration()\n",
    "antsreg.inputs.float = True\n",
    "antsreg.inputs.collapse_output_transforms=True\n",
    "antsreg.inputs.output_transform_prefix = 'rigid_'\n",
    "antsreg.inputs.fixed_image=[]\n",
    "antsreg.inputs.moving_image=[]\n",
    "antsreg.inputs.initial_moving_transform_com=1\n",
    "antsreg.inputs.output_warped_image= True\n",
    "antsreg.inputs.transforms=['Rigid']\n",
    "antsreg.inputs.terminal_output='file'\n",
    "antsreg.inputs.winsorize_lower_quantile=0.005\n",
    "antsreg.inputs.winsorize_upper_quantile=0.995\n",
    "antsreg.inputs.convergence_threshold=[1e-06]\n",
    "antsreg.inputs.convergence_window_size=[10]\n",
    "antsreg.inputs.metric=[['MeanSquares','MI','MI']]\n",
    "antsreg.inputs.metric_weight=[[0.75,0.125,0.125]]\n",
    "antsreg.inputs.number_of_iterations=[[1000, 500, 250, 0]]\n",
    "antsreg.inputs.smoothing_sigmas=[[4, 3, 2, 1]]\n",
    "antsreg.inputs.sigma_units=['vox']\n",
    "antsreg.inputs.radius_or_number_of_bins=[[0,32,32]]\n",
    "antsreg.inputs.sampling_strategy=[['None',\n",
    "                               'Regular',\n",
    "                               'Regular']]\n",
    "antsreg.inputs.sampling_percentage=[[0,0.25,0.25]]\n",
    "antsreg.inputs.shrink_factors=[[12,8,4,2]]\n",
    "antsreg.inputs.transform_parameters=[[(0.1)]]\n",
    "antsreg.inputs.use_histogram_matching=True\n",
    "\n",
    "antsreg_rigid = Node(antsreg,name='antsreg_rigid')\n",
    "#antsreg.cmdline\n",
    "\n",
    "# Apply Rigid Reg node 1\n",
    "\n",
    "apply_rigid_reg = ApplyTransforms()\n",
    "\n",
    "apply_rigid = MapNode(apply_rigid_reg, \n",
    "                      name = 'apply_rigid', \n",
    "                      iterfield=['input_image','reference_image','transforms'], \n",
    "                      nested = True\n",
    "                     )\n",
    "apply_rigid.inputs.input_image = []\n",
    "apply_rigid.inputs.reference_image = []\n",
    "apply_rigid.inputs.transforms = []\n",
    "apply_rigid.inputs.terminal_output = 'file'\n",
    "#apply_rigid_reg.cmdline\n",
    "\n",
    "# Select outputs by image type\n",
    "\n",
    "#Note: could probably make these select nodes iterables for the 'index' field\n",
    "\n",
    "# Select labels\n",
    "\n",
    "sl = Select()\n",
    "sl = Node(sl, name = 'select_lists')\n",
    "sl.inputs.inlist= []\n",
    "sl.inputs.index=[]\n",
    "sl.iterables = ('index', [0,1,2])\n",
    "\n",
    "# Merge selected files into list\n",
    "\n",
    "ml = Merge(1)\n",
    "ml = JoinNode(ml, \n",
    "              name = 'merge_lists',\n",
    "             joinsource = 'info_source',\n",
    "             joinfield = 'in1')\n",
    "ml.inputs.in1 = []\n",
    "ml.inputs.axis = 'hstack'\n",
    "\n",
    "# Average rigid-transformed images to construct new template\n",
    "\n",
    "# TO DO: make this an iterable node\n",
    "\n",
    "avg_rigid = AverageImages()\n",
    "avg_rigid = Node(avg_rigid, name = 'average_rigid')\n",
    "avg_rigid.inputs.dimension = 3\n",
    "avg_rigid.inputs.images = []\n",
    "avg_rigid.inputs.normalize = True\n",
    "avg_rigid.inputs.terminal_output = 'file'\n",
    "\n",
    "#avg_rigid.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x2b9152d712b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish input/output stream\n",
    "\n",
    "#create subject ID iterable\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']), name = \"info_source\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "#create template\n",
    "lhtemplate_files = opj(datadir,'lhtemplate[0, 1, 2].nii.gz')\n",
    "mi_files = opj(datadir,'{subject_id}-*.nii.gz')\n",
    "\n",
    "templates = {'lhtemplate': lhtemplate_files,\n",
    "            'mi': mi_files,\n",
    "            }\n",
    "\n",
    "#select images organized by subject\n",
    "selectfiles = Node(SelectFiles(templates, force_lists=['lhtemplate','mi'], \n",
    "                               sort_filelist = True, \n",
    "                               base_directory=datadir), \n",
    "                               name = \"select_files\")\n",
    "\n",
    "\n",
    "#datasink = Node(DataSink(base_directory= datadir, container = 'output_dir'), name = \"datasink\")\n",
    "#substitutions = [('_subject_id_',''),\n",
    "#                ]\n",
    "\n",
    "#Define function to replicate fwd transforms to match iterfield length\n",
    "def reptrans(forward_transforms):\n",
    "    import numpy as np\n",
    "    nested_list = np.ndarray.tolist(np.tile(forward_transforms,[1,3]))\n",
    "    transforms = [val for sublist in nested_list for val in sublist]\n",
    "    return transforms\n",
    "\n",
    "def flatten_nlist(out):\n",
    "    return [val for sublist in out for val in sublist]\n",
    "\n",
    "# Create pipeline and connect nodes\n",
    "workflow = Workflow(name='normflow')\n",
    "workflow.base_dir = datadir\n",
    "\n",
    "#workflow.add_nodes([test_antsreg_rigid])\n",
    "workflow.connect([\n",
    "                (infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                (selectfiles, antsreg_rigid, [('lhtemplate','fixed_image'),('mi','moving_image')]),\n",
    "                (selectfiles, apply_rigid, [('lhtemplate','reference_image'),('mi','input_image')]),\n",
    "                (antsreg_rigid, apply_rigid, [(('forward_transforms',reptrans),'transforms')]),\n",
    "                (apply_rigid, sl, [('output_image', 'inlist')]),\n",
    "                (sl, ml, [('out','in1')]),\n",
    "                (ml, avg_rigid, [(('out', flatten_nlist),'images')]),\n",
    "                 ])\n",
    "\n",
    "#visualize workflow; makes graph with everything and simplified one\n",
    "import pydotplus\n",
    "#this module isn't included in default dependencies when installing nipype, bc the default only uses pydot\n",
    "workflow.write_graph(graph2use='exec',format='png')\n",
    "workflow.write_graph(graph2use='colored',format='png')\n",
    "\n",
    "# Run the workflow\n",
    "\n",
    "    #try slurmgraph?\n",
    "    \n",
    "workflow.run(plugin='SLURM', plugin_args={'jobid_re': '([0-9]*)', 'sbatch_args': '-t 4 -g 4 --partition nimh'})\n",
    "#workflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      "[1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55, 58, 61, 64, 67, 70, 73, 76, 79, 82, 85, 88, 91, 94, 97, 100]\n",
      "[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n"
     ]
    }
   ],
   "source": [
    "# Scratch pad\n",
    "\n",
    "import numpy as np\n",
    "a = [1,2,3]\n",
    "a = np.ndarray.tolist(np.tile(a,[1,3]))\n",
    "flattened = [val for sublist in a for val in sublist]\n",
    "print(flattened)\n",
    "\n",
    "l = list(range(102))[::3]\n",
    "l2 = [x+1 for x in l]\n",
    "l3 = [x+2 for x in l2]\n",
    "print(l2)\n",
    "print(l3)\n",
    "\n",
    "l4 = list(range(29))\n",
    "print(l4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
